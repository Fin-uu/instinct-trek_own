{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0077b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2b11f",
   "metadata": {},
   "source": [
    "### 2. 檢查伺服器狀態並初始化客戶端\n",
    "\n",
    "此儲存格執行以下操作：\n",
    "1.  **定義伺服器端點**：設定 vLLM 伺服器的基本 URL。\n",
    "2.  **檢查可用模型**：向 `/models` 端點發送 GET 請求，以擷取伺服器上可用的模型列表。\n",
    "3.  **設定模型名稱**：從回應中提取模型名稱以供後續請求使用。如果伺服器無法連線或沒有模型可用，則會使用預設名稱。\n",
    "4.  **初始化 OpenAI 客戶端**：建立 `OpenAI` 客戶端的實例，並將其設定為指向 vLLM 伺服器的 `base_url`。`api_key` 設定為虛擬金鑰，因為此本地伺服器不需要身份驗證。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda539eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先檢查伺服器狀態\n",
    "import requests\n",
    "\n",
    "# 檢查可用模型\n",
    "vllm_gpt_oss_120b_1=\"http://210.61.209.139:45014/v1/\"\n",
    "vllm_gpt_oss_120b_2=\"http://210.61.209.139:45005/v1/\"\n",
    "\n",
    "base_url = vllm_gpt_oss_120b_1\n",
    "try:\n",
    "    response = requests.get(base_url+\"models\")\n",
    "    models = response.json()\n",
    "    print(\"Available models:\", models)\n",
    "    \n",
    "    # 取得實際的模型名稱\n",
    "    if models.get(\"data\"):\n",
    "        model_name = models[\"data\"][0][\"id\"]\n",
    "        print(f\"Using model: {model_name}\")\n",
    "    else:\n",
    "        print(\"No models available!\")\n",
    "        model_name = \"gpt-oss-120b\"  # 預設值\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to vLLM server: {e}\")\n",
    "    model_name = \"gpt-oss-120b\"\n",
    "\n",
    "# 初始化 OpenAI 客戶端\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=\"dummy-key\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa18305",
   "metadata": {},
   "source": [
    "### 3. 文字生成測試\n",
    "\n",
    "此儲存格使用 `client.completions.create` 方法測試基本文字生成功能。\n",
    "\n",
    "它會：\n",
    "1.  發送一個簡單的提示 (`\"Once upon a time in a magical forest,\"`)。\n",
    "2.  列印生成的文字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a84a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文字生成測試 \n",
    "\n",
    "message=\"Once upon a time in a magical forest,\"\n",
    "\n",
    "try:\n",
    "    \n",
    "    response = client.completions.create(\n",
    "        model=model_name,\n",
    "        prompt=message,\n",
    "        max_tokens=100,\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    generated_text = response.choices[0].text\n",
    "    print(\"Prompt:\", message)\n",
    "    print(\"Generated text:\", generated_text)\n",
    "    \n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69c8adb",
   "metadata": {},
   "source": [
    "### 4. 聊天補全測試\n",
    "\n",
    "此儲存格使用 `client.chat.completions.create` 方法測試聊天功能。此方法更適合對話式或指令式的互動。\n",
    "\n",
    "它會：\n",
    "1.  發送包含系統訊息（設定助理的行為）和使用者訊息（問題）的對話歷史記錄。\n",
    "2.  列印模型的聊天回應。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c08a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat completion 測試\n",
    "\n",
    "try:\n",
    "   \n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Explain machine learning in one paragraph.\"}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    response_content = chat_response.choices[0].message.content\n",
    "    print(\"Chat response:\", response_content)\n",
    "    \n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Chat error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306c3f42",
   "metadata": {},
   "source": [
    "### 5. 推理能力測試 - 複雜邏輯謎題\n",
    "\n",
    "此儲存格旨在透過給予一個需要逐步推理的複雜邏輯謎題來評估模型的推理能力。\n",
    "\n",
    "它會：\n",
    "1.  使用系統提示，指示模型「逐步思考」。\n",
    "2.  提供一個包含多個線索的邏輯謎題。\n",
    "3.  將 `temperature` 設定為較低的值 (`0.1`)，以鼓勵更具確定性和邏輯性的一致回應。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6803ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasoning Effort 測試 - 複雜推理任務\n",
    "\n",
    "try:\n",
    "    \n",
    "    reasoning_response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert problem solver. Think step by step and show your reasoning process.\"},\n",
    "            {\"role\": \"user\", \"content\": \"\"\"\n",
    "            Solve this logic puzzle step by step:\n",
    "            \n",
    "            Three friends - Alice, Bob, and Carol - each have a different pet (cat, dog, bird) and live in different colored houses (red, blue, green).\n",
    "            \n",
    "            Clues:\n",
    "            1. Alice doesn't live in the red house\n",
    "            2. The person with the cat lives in the blue house\n",
    "            3. Bob doesn't have a bird\n",
    "            4. Carol doesn't live in the green house\n",
    "            5. The person in the red house has a dog\n",
    "            \n",
    "            Who has which pet and lives in which house?\n",
    "            \"\"\"}\n",
    "        ],\n",
    "        temperature=0.1,  # 低溫度確保邏輯一致性\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    \n",
    "    reasoning_content = reasoning_response.choices[0].message.content\n",
    "    print(\"Reasoning Response:\", reasoning_content)\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Reasoning error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c98599",
   "metadata": {},
   "source": [
    "### 6. 推理能力測試 - 數學問題\n",
    "\n",
    "此儲存格透過一個需要基本數學計算的簡單問題，繼續測試模型的推理能力。\n",
    "\n",
    "它會：\n",
    "1.  要求模型解決一個關於速度和距離的數學應用題，並「展示其解題過程」。\n",
    "2.  此測試中的 `reasoning_effort=\"high\"` 是一個範例參數，用於展示如何向 API 發出需要更強推理能力的信號（請注意，此參數可能並非在所有 vLLM 設定中都為標準功能）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3868667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 簡化推理測試 - 數學問題\n",
    "\n",
    "try:\n",
    "\n",
    "    system_prompt=\"You are a helpful math tutor. Solve problems step by step.\"\n",
    "    user_prompt=\"A train travels 120 km in 2 hours. If it maintains the same speed, how far will it travel in 5 hours? Please show your work.\"\n",
    "    \n",
    "    math_response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=200,\n",
    "        reasoning_effort=\"high\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    math_content = math_response.choices[0].message.content\n",
    "    print(\"\\n\")\n",
    "    print(\"Prompt:\", user_prompt)\n",
    "    print(\"\\nMath Reasoning Response:\", math_content)\n",
    "    \n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Math reasoning error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27fc5c0",
   "metadata": {},
   "source": [
    "### 7. 模型診斷測試\n",
    "\n",
    "此最後一個儲存格執行快速診斷，以檢查模型輸出的基本品質和健全性。\n",
    "\n",
    "它會：\n",
    "1.  迭代一組簡單、多樣的提示（一個數學問題、一個解釋性問題和一個列表請求）。\n",
    "2.  對於每個提示，它會擷取回應並測量延遲。\n",
    "3.  執行基本的品質檢查：\n",
    "    - 確保回應不為空。\n",
    "    - 檢查字元多樣性，以標記潛在的重複性問題（例如，模型輸出重複的字元）。\n",
    "4.  根據檢查結果列印成功或警告訊息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557636f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型診斷測試 - 檢查輸出品質\n",
    "\n",
    "try:\n",
    "    # 測試不同的提示策略\n",
    "    prompts = [\n",
    "        \"What is 2+2?\",\n",
    "        \"Explain photosynthesis briefly.\",\n",
    "        \"List 3 colors.\"\n",
    "    ]\n",
    "    \n",
    "    for i, prompt in enumerate(prompts, 1):\n",
    "        print(f\"\\n--- Test {i}: {prompt} ---\")\n",
    "\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[ \n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.5,\n",
    "            max_tokens=50\n",
    "        )\n",
    "        \n",
    " \n",
    "        \n",
    "        content = response.choices[0].message.content\n",
    "        print(f\"Response: {content}\")\n",
    "        \n",
    "        # 檢查輸出品質\n",
    "        if content and len(content.strip()) > 0:\n",
    "            # 檢查是否有重複字符（如感嘆號問題）\n",
    "            if len(set(content)) < 5:  # 如果字符種類太少\n",
    "                print(\"⚠️ Warning: Low character diversity - possible repetition issue\")\n",
    "            else:\n",
    "                print(\"✅ Output looks normal\")\n",
    "        else:\n",
    "            print(\"❌ Empty or invalid response\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Diagnostic error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
